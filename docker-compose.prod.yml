# ========================================
# Docker Compose - Production Configuration
# Optimized for deployment on cloud platforms
# ========================================

version: '3.8'

services:
  # ========================================
  # Backend API Service - Production
  # ========================================
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile.lightweight
      cache_from:
        - python:3.11-slim
    container_name: review-intelligence-api-prod
    restart: always
    ports:
      - "${PORT:-8000}:8000"
    environment:
      # Production Settings
      - DEBUG=False
      - ENVIRONMENT=production
      - HOST=0.0.0.0
      - PORT=8000
      - WORKERS=4
      
      # API Keys (from environment or secrets)
      - APIFY_API_TOKEN=${APIFY_API_TOKEN}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      
      # Features
      - ENABLE_AI=${ENABLE_AI:-True}
      - ENABLE_EMOTIONS=${ENABLE_EMOTIONS:-True}
      - ENABLE_CACHING=${ENABLE_CACHING:-True}
      
      # Performance
      - MAX_REVIEWS_PER_REQUEST=${MAX_REVIEWS_PER_REQUEST:-100}
      - CACHE_TTL=${CACHE_TTL:-3600}
      
      # CORS (update with your frontend URL)
      - ALLOWED_ORIGINS=${ALLOWED_ORIGINS:-https://your-frontend.vercel.app}
      
      # Redis
      - REDIS_URL=redis://redis:6379/0
      
      # Monitoring (optional)
      - SENTRY_DSN=${SENTRY_DSN:-}
    
    volumes:
      # Persist data and logs
      - backend-data:/app/data
      - backend-exports:/app/exports
      - backend-logs:/app/logs
    
    networks:
      - app-network
    
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    
    depends_on:
      redis:
        condition: service_healthy
    
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # ========================================
  # Redis Cache - Production
  # ========================================
  redis:
    image: redis:7-alpine
    container_name: review-intelligence-redis-prod
    restart: always
    command: >
      redis-server
      --appendonly yes
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis-data:/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"

  # ========================================
  # Nginx Reverse Proxy (Optional)
  # ========================================
  # nginx:
  #   image: nginx:alpine
  #   container_name: review-intelligence-nginx
  #   restart: always
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
  #     - ./nginx/ssl:/etc/nginx/ssl:ro
  #   depends_on:
  #     - backend
  #   networks:
  #     - app-network

# ========================================
# Networks
# ========================================
networks:
  app-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16

# ========================================
# Volumes
# ========================================
volumes:
  backend-data:
    driver: local
  backend-exports:
    driver: local
  backend-logs:
    driver: local
  redis-data:
    driver: local
